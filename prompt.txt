Please read carefully the README.md and the whisperx.md files. Then read all the code within all the rust files in the src directory and take a good attention to the inline comments. Finally, compose a very detailed prompt about what and how does this project with technical details so you could use this prompt to understand the current project status at once. Please edit the prompt.txt file and write this detailed prompt under the line with stars "********************"
@file: src

***********************************************************************************************************************************************************************

# Whisper API: A Robust Rust-based API for Audio Transcription with WhisperX

## Project Overview
This project implements a high-performance HTTP API for audio transcription using WhisperX. Built in Rust with the Actix-web framework, it features a modular architecture with a queue-based processing system that handles multiple concurrent requests while managing system resources efficiently through sequential processing. The API provides clients with an asynchronous workflow for submitting audio files, monitoring transcription progress, and retrieving results with optional speaker diarization.

## Core Architecture Components

### 1. Modular Code Organization
The codebase follows a modular design pattern with clear separation of concerns:
- **config.rs**: Centralizes configuration management and environment variable handling
- **error.rs**: Implements comprehensive error types with proper HTTP status code mapping
- **file_utils.rs**: Manages file operations with resource cleanup guarantees
- **handlers/**: Contains HTTP endpoint implementations with form processing logic
  - **handlers/mod.rs**: Defines the module structure and re-exports handlers for use in main.rs
  - **handlers/form.rs**: Handles multipart form data extraction, parameter validation, and file processing with detailed error handling and HuggingFace token fallback mechanisms
  - **handlers/routes.rs**: Implements the four main API endpoints (transcribe, transcription_status, transcription_result, cancel_transcription) with proper request handling and response formatting
- **models.rs**: Defines data structures for requests, responses, and internal state
- **queue_manager.rs**: Implements the job queue and transcription processing pipeline
- **main.rs**: Initializes the application, configures routes, and starts the HTTP server

### 2. Queue Manager (`queue_manager.rs`)
- Implements a FIFO transcription job queue using thread-safe `Arc<Mutex<>>` wrappers
- Utilizes Tokio's asynchronous runtime for non-blocking, efficient IO operations
- Enforces sequential job processing (one at a time) to prevent GPU resource contention
- Maintains job state (Queued, Processing, Completed, Failed) with automatic transitions
- Handles the complete job lifecycle from submission through processing to cleanup
- Features a configurable automatic job expiration system (default: 48 hours retention)
- Provides a clean API for job management (status checks, result retrieval, cancellation)
- Validates and processes various output formats (srt, vtt, txt, tsv, json, aud)

### 3. HTTP Request Handling
- RESTful API endpoints implemented with Actix-web for high performance
- Multipart form data handling for audio file uploads (supports files up to 512MB)
- Unique job IDs generated using UUIDs to prevent collisions
- Job-specific temporary directories for secure file isolation
- Comprehensive error handling with appropriate HTTP status codes
- Optional HuggingFace token handling with fallback to file-based configuration
- Automatic disabling of diarization when no token is available

### 4. WhisperX Integration
- Executes WhisperX as an external command-line process with proper error handling
- Configurable parameters including:
  - Model selection (tiny to large-v3, default: large-v3)
  - Language specification (default: fr)
  - Speaker diarization with HuggingFace token support
  - Initial prompts for context-aware transcription
  - Multiple output formats (srt, vtt, txt, tsv, json, aud)
- File-based result handling with proper path management
- Structured result parsing and delivery to clients

## Technical Implementation Details

### Concurrent Request Handling with Sequential Processing
1. **HTTP Layer**:
   - Actix-web provides asynchronous HTTP request handling
   - Multiple concurrent clients can submit transcription requests
   - Each request is processed independently up to the queuing stage
   - Form data processing is handled in isolation with proper resource management

2. **Queue Management**:
   - Uses `Arc<Mutex<QueueState>>` to provide thread-safe access to shared state
   - Implements a single-producer, multiple-consumer (mpsc) channel for job dispatching
   - The `processing` flag ensures only one job runs at a time
   - Lock acquisition patterns carefully designed to prevent deadlocks:
     ```rust
     let queue_manager = queue_manager.lock().await;
     queue_manager.add_job(job).await?;
     ```

3. **Background Processing**:
   - Dedicated async task runs independently of the HTTP request lifecycle
   - Listens on the job channel and processes jobs sequentially
   - Automatically chains job processing to maintain FIFO order
   - Manages state transitions and error handling

### Job Processing Workflow
1. **Submission** (`POST /transcribe`):
   - Client submits audio file and parameters via multipart form
   - Server validates input and parameters
   - Unique directory created for job isolation
   - If HuggingFace token not provided in request, attempts to read from file
   - Job added to queue and client receives job ID and status URL

2. **Processing**:
   - Background processor dequeues jobs one at a time
   - WhisperX command constructed with appropriate parameters
   - Command executed and monitored for completion
   - Output files read and parsed into result structure
   - Job status updated based on success or failure

3. **Status Checking** (`GET /transcription/{job_id}`):
   - Client polls status endpoint using job ID
   - Server responds with current status (Queued, Processing, Completed, Failed)
   - No file system operations during status checks for efficiency

4. **Result Retrieval** (`GET /transcription/{job_id}/result`):
   - Client requests final transcription when status is Completed
   - Server returns structured JSON with transcription text and metadata
   - Temporary files automatically cleaned up after successful delivery
   - Error handling for cases where job is not complete or has failed

5. **Cancellation** (`DELETE /transcription/{job_id}`):
   - Client can cancel queued jobs (not applicable to in-progress jobs)
   - Server removes job from queue and cleans up associated resources
   - Confirmation or error message returned based on outcome

### Security and Privacy Features
- **Isolated File Storage**:
   ```rust
   // Each job gets a unique UUID-based directory
   let uuid = Uuid::new_v4();
   let folder_name = uuid.to_string();
   let directory_path = Path::new(base_dir).join(&folder_name);
   ```

- **Multi-layered Cleanup Mechanisms**:
   - Immediate cleanup after result delivery
   - Error path cleanup to prevent orphaned files
   - Cancellation cleanup for aborted jobs
   - Background periodic cleanup for expired jobs (48-hour retention)

- **Resource Protection**:
   - File size validation (max 512MB)
   - Sequential processing to prevent GPU exhaustion
   - Proper error handling to ensure resource release
   - Configurable timeouts to prevent hung connections

### Error Handling Architecture
- **Error Types Hierarchy**:
   ```rust
   #[derive(Error, Debug)]
   pub enum HandlerError {
       #[error("Form error: {0}")]
       FormError(String),

       #[error("File error: {0}")]
       FileError(#[from] io::Error),

       // Additional error variants for different scenarios
   }
   ```

- **HTTP Status Code Mapping**:
   ```rust
   impl ResponseError for HandlerError {
       fn error_response(&self) -> HttpResponse {
           // Maps error types to appropriate HTTP status codes
           match self {
               HandlerError::NoAudioFile => HttpResponse::BadRequest().json(...),
               HandlerError::JobNotFound(_) => HttpResponse::NotFound().json(...),
               HandlerError::FileTooLarge(_, _) => HttpResponse::PayloadTooLarge().json(...),
               // Other mappings
           }
       }
   }
   ```

- **Resource Cleanup on Error**:
   ```rust
   // Automatic cleanup when errors occur
   pub fn with_cleanup(self, folder: Option<&PathBuf>) -> Self {
       if let Some(folder) = folder {
           crate::file_utils::cleanup_folder(folder);
       }
       self
   }
   ```

### Configuration System
- **Environment Variables with Defaults**:
   ```rust
   // Environment variable loading with defaults
   fn default() -> Self {
       Self {
           temp_dir: env::var("WHISPER_TMP_FILES")
               .unwrap_or_else(|_| String::from(defaults::TEMP_DIR)),
           hf_token_file: env::var("WHISPER_HF_TOKEN_FILE")
               .unwrap_or_else(|_| String::from(defaults::HF_TOKEN_FILE)),
       }
   }
   ```

- **Centralized Configuration Constants**:
   ```rust
   pub mod defaults {
       pub const TEMP_DIR: &str = "/home/llm/whisper_api/tmp";
       pub const LANGUAGE: &str = "fr";
       pub const MODEL: &str = "large-v3";
       pub const HF_TOKEN_FILE: &str = "/home/llm/whisper_api/hf_token.txt";
       pub const VALID_OUTPUT_FORMATS: [&str; 6] = ["srt", "vtt", "txt", "tsv", "json", "aud"];
   }
   ```

### HuggingFace Token Handling
- **Multi-source Token Resolution**:
  1. First tries to use token provided in request parameters
  2. If not provided, attempts to read from configured token file (`hf_token.txt`)
  3. If file is missing, empty, or unreadable, disables diarization
  
- **HuggingFace Token File**:
  - Default location: `/home/llm/whisper_api/hf_token.txt`
  - Configurable via `WHISPER_HF_TOKEN_FILE` environment variable
  - Contains plain text HuggingFace API token with no formatting requirements
  - System automatically trims whitespace from token when reading
  - No token in file results in automatic diarization disabling
  - Prevents need to include token in every API request
  - Provides centralized management of authentication credentials
  
- **Automatic Diarization Fallback**:
  ```rust
  // If no token is available, disable diarization
  if params.hf_token.is_none() {
      let hf_token_path = std::path::Path::new(&config.hf_token_file);
      if hf_token_path.exists() {
          match read_text_file(hf_token_path) {
              Ok(token) => {
                  // Use token from file
              }
              Err(_) => {
                  // Disable diarization if token cannot be read
                  if params.diarize {
                      warn!("Disabling diarization because no HuggingFace token is available");
                      params.diarize = false;
                  }
              }
          }
      }
  }
  ```

## API Endpoints Documentation

### 1. Submit Transcription (`POST /transcribe`)
- **Purpose**: Upload audio file and start transcription
- **Form Parameters**:
  - `file`: Audio file (required, max 512MB)
  - `language`: Language code (optional, default: "fr")
  - `model`: Model name (optional, default: "large-v3")
  - `diarize`: Enable speaker diarization (optional, default: true)
  - `prompt`: Initial transcription prompt (optional)
  - `hf_token`: HuggingFace token for diarization (optional, if not provided will attempt to read from `hf_token.txt` file)
  - `output_format`: Result format (optional, default: "txt")
- **Response**: Job ID and status URL
- **Error Handling**: File size validation, format validation, server errors

### 2. Check Status (`GET /transcription/{job_id}`)
- **Purpose**: Monitor transcription progress
- **Path Parameters**: `job_id` (UUID from submission)
- **Response**: Current job status (Queued, Processing, Completed, Failed)
- **Error Handling**: Job not found, server errors

### 3. Get Result (`GET /transcription/{job_id}/result`)
- **Purpose**: Retrieve completed transcription
- **Path Parameters**: `job_id` (UUID from submission)
- **Response**: Transcription text, language, and segments
- **Error Handling**: Job not found, job not completed, server errors
- **Side Effects**: Triggers cleanup of job files after delivery

### 4. Cancel Job (`DELETE /transcription/{job_id}`)
- **Purpose**: Cancel pending transcription
- **Path Parameters**: `job_id` (UUID from submission)
- **Response**: Success confirmation or error message
- **Error Handling**: Job not found, job already processing, server errors
- **Side Effects**: Removes job files if successfully canceled

## Deployment Requirements
- **Runtime Dependencies**:
  - Rust with Tokio async runtime
  - WhisperX executable and models accessible via path
  - GPU support for efficient transcription processing
  - Sufficient disk space for temporary files and results
  - HuggingFace token file (`/home/llm/whisper_api/hf_token.txt` by default) if diarization support needed
    - File should contain only the API token as plain text
    - Optional - system will operate without it but diarization will be disabled

- **Environment Configuration**:
  - 15+ configurable environment variables for customization
  - Defaults suitable for standard deployments
  - `WHISPER_HF_TOKEN_FILE` variable to specify custom location for HuggingFace token file
  - Documentation in README.md for all settings

## Current Status and Limitations
- **Fully Implemented Features**:
  - Complete API with all endpoints functional
  - Queue management with sequential processing
  - File isolation and cleanup processes
  - Error handling and logging
  - Configuration via environment variables
  - HuggingFace token handling with fallback mechanisms

- **Limitations**:
  - No authentication or rate limiting (open API)
  - No streaming results for long transcriptions
  - Limited metrics and monitoring capabilities
  - No built-in health checks or readiness probes
  - Single-instance design (no distributed queuing)
  - Audio file limited to 512MB maximum size

## Future Enhancement Opportunities
- Authentication and authorization system
- Metrics collection for performance monitoring
- Health check endpoints for deployment monitoring
- Rate limiting to prevent API abuse
- Support for batch processing of multiple files
- Streaming API for large transcription jobs
- Distributed queue for multi-instance deployments
- Enhanced logging for better diagnostics
